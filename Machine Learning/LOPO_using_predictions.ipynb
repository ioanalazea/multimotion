{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMBam5zBvBiY"
      },
      "source": [
        "**LOPO using predictions**\n",
        "\n",
        "---\n",
        "\n",
        "Instead of training the fusion model directly on raw featured, used the predictions from each modality as inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OeRqVBnvLhP",
        "outputId": "228aaf3e-c75e-432d-f069-b25291151d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob1YU8_dqnYy"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "import statsmodels.api as sm\n",
        "from lightgbm import LGBMRegressor\n",
        "from typing import List\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g-zOJ7evhYr"
      },
      "outputs": [],
      "source": [
        "# Defining the directoryies\n",
        "home = r\"/content/drive/MyDrive/Data-Multimotion\"\n",
        "full_video_directory = r\"/content/drive/MyDrive/Data-Multimotion/Features-NEW/Full\"\n",
        "intervals_directory = r\"/content/drive/MyDrive/Data-Multimotion/Features-NEW/Intervals\"\n",
        "ground_truth_directory = r\"/content/drive/MyDrive/Data-Multimotion/Ground truth\"\n",
        "results_directory = r\"/content/drive/MyDrive/Data-Multimotion/Results\"\n",
        "predictions_directory = r\"/content/drive/MyDrive/Data-Multimotion/Predictions/LOPO\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgE-zTk4vrcz"
      },
      "source": [
        "**Loading the data** - will be using **only** Pupil and GSR now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yHCjXFgvcGv"
      },
      "outputs": [],
      "source": [
        "# Full Pupil - loading the csv\n",
        "df_pupil_full = pd.read_csv(os.path.join(full_video_directory, \"Not_Interval_60_part_all_stat_features_12062025.csv\"))\n",
        "df_pupil_full.rename(columns={\"Participant\": \"participant\", \"simuli_name_1\": \"video\"}, inplace=True)\n",
        "df_pupil_full.drop(columns=['Arousal', 'Valence', 'simuli_name_2','Unnamed: 0'], inplace=True)\n",
        "\n",
        "# Intervals - Loading the csv\n",
        "df_pupil_interval = pd.read_csv(os.path.join(intervals_directory, \"Interval_60_part_all_stat_features_01062025.csv\"))\n",
        "df_pupil_interval.rename(columns={\"Participant\": \"participant\", \"simuli_name_1\": \"video\"}, inplace=True)\n",
        "df_pupil_interval.drop(columns=['Arousal', 'Valence', 'simuli_name_2', 'Unnamed: 0'], inplace=True)\n",
        "\n",
        "# Merging the intervals and full GSR features\n",
        "df_pupil = pd.merge(df_pupil_full, df_pupil_interval, on=['participant', 'video'],\n",
        "                    suffixes=('_whole', '_interval'))\n",
        "\n",
        "# Full GSR - Loading the csv\n",
        "df_gsr_full = pd.read_csv(os.path.join(full_video_directory, \"gsr_features.csv\"))\n",
        "df_gsr_full.rename(columns={\"ParticipantID\": \"participant\", \"StimulusName\": \"video\"}, inplace=True)\n",
        "\n",
        "# Intervals GSR - Loading the csv\n",
        "df_gsr_intervals = pd.read_csv(os.path.join(intervals_directory, \"gsr_features_intervals.csv\"))\n",
        "df_gsr_intervals.rename(columns={\"ParticipantID\": \"participant\", \"StimulusName_0\": \"video\"}, inplace=True)\n",
        "\n",
        "# Merging the intervals and full GSR features\n",
        "df_gsr = pd.merge(df_gsr_full, df_gsr_intervals, on=['participant', 'video'],\n",
        "                  suffixes=('_whole', '_interval'))\n",
        "\n",
        "\n",
        "participant_col = 'participant'\n",
        "video_col = 'video'\n",
        "\n",
        "pupil_features = [col for col in df_pupil.columns if col not in [participant_col, video_col]]\n",
        "gsr_features = [col for col in df_gsr.columns if col not in [participant_col, video_col]]\n",
        "\n",
        "\n",
        "# Merge df_fer and df_pupil first\n",
        "df = pd.merge( df_gsr,df_pupil, on=['participant', 'video'], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF_NVDcDfU0q",
        "outputId": "041a7360-a5e5-4de7-ec95-aa5a95975989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Participants Pupil: 59\n",
            "Participants GSR: 59\n",
            "Participants merged: 56\n"
          ]
        }
      ],
      "source": [
        "print('Participants Pupil:', len(df_pupil['participant'].unique()))\n",
        "print('Participants GSR:', len(df_gsr['participant'].unique()))\n",
        "print('Participants merged:', len(df['participant'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzoOcvDavZdd"
      },
      "source": [
        "**Cleaning** the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKAM3jTT1OgQ",
        "outputId": "a123e530-6daf-458b-f691-0a7d522d8ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corr_kurtosis_whole       1619\n",
            "corr_skewness_whole       1619\n",
            "corr_auc_whole            1619\n",
            "diff_kurtosis_whole       1619\n",
            "diff_skewness_whole       1619\n",
            "diff_auc_whole            1619\n",
            "corr_kurtosis_interval     668\n",
            "corr_skewness_interval     668\n",
            "corr_auc_interval          668\n",
            "diff_kurtosis_interval     668\n",
            "diff_skewness_interval     668\n",
            "diff_auc_interval          668\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Get columns with NaNs and sort by number of NaNs\n",
        "nan_summary = df.isnull().sum()\n",
        "nan_summary = nan_summary[nan_summary > 0].sort_values(ascending=False)\n",
        "\n",
        "# Display the columns NaNs\n",
        "print(nan_summary.head(100))\n",
        "\n",
        "# Get column names with NaNs\n",
        "missing_cols = nan_summary.index.tolist()\n",
        "\n",
        "# Impute missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[missing_cols] = imputer.fit_transform(df[missing_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8_gX6zf0LrJ"
      },
      "source": [
        "**Ground truth**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs-QtHxxwlB6"
      },
      "outputs": [],
      "source": [
        "# Load full ground truth (this is done only once)\n",
        "gt_full_set = pd.read_csv(os.path.join(ground_truth_directory, \"individual_ground_truth.csv\"))\n",
        "\n",
        "# Renaming so it is the same as FER and Pupil\n",
        "gt_full_set.rename(columns={\"Participant\": \"participant\", \"Stimulus_Name\": \"video\"}, inplace=True)\n",
        "\n",
        "def load_ground_truth_exclude(participant_id):\n",
        "    \"\"\" Function to load ground truth file for excluding one participant for Leave One Participant Out \"\"\"\n",
        "    # Construct the file path\n",
        "    file_path = os.path.join(\n",
        "        ground_truth_directory,\n",
        "        f\"Leave-one-out/individual_ground_truth_no_{participant_id}.csv\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        gt_df = pd.read_csv(file_path)\n",
        "        return gt_df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"[Warning] Ground truth file not found for participant {participant_id} at: {file_path}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgpy77j6wlMb"
      },
      "outputs": [],
      "source": [
        "def get_train_test_data(df, gt_full_set, test_pid, target):\n",
        "    \"\"\" Split data into train and test and merge with ground truth.\"\"\"\n",
        "    test_data = df[df[\"participant\"] == test_pid].copy()\n",
        "    test_gt = gt_full_set[gt_full_set[\"participant\"] == test_pid]\n",
        "    test_data = test_data.merge(\n",
        "    test_gt[[\"participant\", \"video\", target]],\n",
        "      on=[\"participant\", \"video\"],\n",
        "          how=\"inner\",\n",
        "      )\n",
        "\n",
        "    train_data = df[df[\"participant\"] != test_pid].copy()\n",
        "\n",
        "    pid_gt = load_ground_truth_exclude(test_pid)\n",
        "    if pid_gt is not None:\n",
        "      pid_gt.rename(\n",
        "            columns={\"Participant\": \"participant\", \"Stimulus_Name\": \"video\"}, inplace=True\n",
        "        )\n",
        "\n",
        "      train_data = train_data.merge(\n",
        "            pid_gt[[\"participant\", \"video\", target]],\n",
        "            on=[\"participant\", \"video\"],\n",
        "            how=\"inner\",\n",
        "        )\n",
        "\n",
        "      return train_data, test_data\n",
        "    else:\n",
        "      return None, None\n",
        "\n",
        "\n",
        "def evaluate_fusion_model(y_true, y_pred):\n",
        "    \"\"\" Calculate evaluation metrics .\"\"\"\n",
        "    rmse = root_mean_squared_error(y_true, y_pred)\n",
        "    nrmse = rmse / (y_true.max() - y_true.min())\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    corr, p_val = pearsonr(y_true, y_pred)\n",
        "    return {\"NRMSE\": nrmse, \"R2\": r2, \"corr\": corr, \"p\": p_val}\n",
        "\n",
        "def print_filtered_summary(results_df):\n",
        "    filtered = results_df[\n",
        "        (results_df['R2'] > -1.0) &                 # Removes models with extremely poor fit\n",
        "        (results_df['NRMSE'] < 1.5) &              # Removes predictions with very high error\n",
        "        (results_df['corr'].abs() > 0.2)           # Keeps only modestly correlated results\n",
        "    ]\n",
        "    summary_filtered = filtered[['NRMSE', 'R2', 'corr', 'p']].agg(['mean', 'std'])\n",
        "    print(\"\\n=== Summary (Excluding Outliers) ===\")\n",
        "    print(f\"\\nFiltered out {len(results_df) - len(filtered)} out of {len(results_df)} participants.\")\n",
        "    print(summary_filtered.round(4))\n",
        "    excluded = results_df[~results_df.index.isin(filtered.index)]\n",
        "    print(\"\\nExcluded participants:\")\n",
        "    print(excluded[['participant', 'NRMSE', 'R2', 'corr']])\n",
        "\n",
        "def print_fusion_weights_summary(fusion_weights):\n",
        "    if fusion_weights:\n",
        "        weights_df = pd.DataFrame(fusion_weights).T\n",
        "        weights_df.columns = ['Pupil_weight', 'GSR_weight']\n",
        "        print(\"\\nAverage Fusion Weights across Participants:\")\n",
        "        print(weights_df.mean().round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHhQ53FjvxU5"
      },
      "source": [
        "Define the **GSR model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvFrlmb9rqPj"
      },
      "outputs": [],
      "source": [
        "# GSR parameters for arousal and the features used\n",
        "gsr_modality_configs = {\n",
        "    \"GSR_arousal\": {\n",
        "        \"params\": {\n",
        "            # SVR\n",
        "            \"kernel\": \"rbf\",\n",
        "            \"degree\": 2,\n",
        "            \"gamma\": 1e-4,\n",
        "            \"coef0\": 1,\n",
        "            \"tol\": 5e-3,\n",
        "            \"C\": 0.5,\n",
        "            \"epsilon\": 0.05,\n",
        "\n",
        "            # LGBM\n",
        "            \"num_leaves\": 31,\n",
        "            \"max_depth\": -1,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"n_estimators\": 300,\n",
        "            \"min_child_samples\": 20,\n",
        "            \"subsample\": 0.6,\n",
        "            \"colsample_bytree\": 0.6,\n",
        "        },\n",
        "\n",
        "        \"svr_features\": [\n",
        "            'freqKurtEDA_whole', 'freqKurtEDA_interval', 'entropyWavelet_4_interval', 'medianMFCC_1_whole',\n",
        "            'meanMFCC_1_interval', 'complexity_interval', 'energyDistribution_4_interval',\n",
        "            'meanDerivative_whole', 'energyDistribution_0_whole', 'energyDistribution_1_whole',\n",
        "            'energyDistribution_2_whole', 'energyDistribution_3_whole', 'meanNegativeSecondDerivative_whole',\n",
        "            'phasicPowers_1_whole'\n",
        "        ],\n",
        "        \"lgbm_features\": [\n",
        "            \"freqKurtEDA_whole\", \"freqKurtEDA_interval\", \"freqSkewEDA_whole\", \"freqSkewEDA_interval\",\n",
        "            \"energyDistribution_0_whole\", \"stdMFCC_12_interval\", \"stdMFCC_11_whole\", \"stdMFCC_11_interval\",\n",
        "            \"stdMFCC_10_interval\", \"stdMFCC_12_whole\", \"spectralPowerBand(0.3-0.4)_interval\",\n",
        "            \"energyDistribution_1_whole\", \"energyDistribution_0_interval\",\n",
        "            \"spectralPowerBand(0.4-0.5)_interval\", \"energyWavelet_3_interval\", \"energyWavelet_2_interval\",\n",
        "            \"sumAreas_interval\", \"meanNegativeSecondDerivative_whole\", \"energyDistribution_2_whole\",\n",
        "            \"energyDistribution_2_interval\", \"phasicPowers_1_whole\", \"kurtMFCC_12_interval\",\n",
        "            \"entropyWavelet_0_whole\", \"stdMFCC_10_whole\", \"energyDistribution_8_interval\",\n",
        "            \"energyWavelet_0_interval\", \"hoc_5_whole\", \"skewMFCC_12_interval\", \"skewMFCC_10_interval\",\n",
        "            \"energyDistribution_6_whole\", \"energyDistribution_8_whole\", \"medianMFCC_10_interval\",\n",
        "            \"activity_interval\", \"meanMFCC_6_interval\", \"rmsWavelet_3_interval\", \"energyWavelet_2_whole\",\n",
        "            \"hoc_1_whole\", \"stdMFCC_1_whole\", \"spectralPowerBand(0.2-0.3)_interval\",\n",
        "            \"meanMFCC_11_interval\", \"medianMFCC_12_interval\", \"energyDistribution_4_interval\",\n",
        "            \"stdMFCC_9_whole\", \"skewMFCC_1_interval\", \"skewMFCC_8_interval\", \"medianMFCC_2_interval\",\n",
        "            \"meanSecondDerivative_interval\", \"meanMFCC_12_interval\", \"energyDistribution_4_whole\",\n",
        "            \"meanMFCC_7_interval\"\n",
        "        ]\n",
        "    },\n",
        "        \"GSR_valence\": {\n",
        "        \"params\": {\n",
        "            # SVR\n",
        "            \"kernel\": \"rbf\",\n",
        "            \"degree\": 2,\n",
        "            \"gamma\": 5e-4,\n",
        "            \"coef0\": 1,\n",
        "            \"tol\": 1e-3,\n",
        "            \"C\": 1,\n",
        "            \"epsilon\": 5e-1,\n",
        "\n",
        "            # LGBM\n",
        "            \"num_leaves\": 31,\n",
        "            \"max_depth\": -1,\n",
        "            \"learning_rate\": 0.1,\n",
        "            \"n_estimators\": 500,\n",
        "            \"min_child_samples\": 40,\n",
        "            \"subsample\": 0.6,\n",
        "            \"colsample_bytree\": 0.6,\n",
        "        },\n",
        "        \"svr_features\": [\n",
        "            \"freqKurtEDA_whole\", \"freqKurtEDA_interval\",\"kurtMFCC_2_interval\",\n",
        "            \"hoc_0_interval\", \"skewEDA_interval\",\"skewMFCC_5_interval\",\n",
        "            \"skewMFCC_6_interval\", \"meanPeakAmplitude_interval\",\"stdMFCC_2_interval\",\n",
        "            \"stdEDA_interval\",\"meanMFCC_3_interval\",\"meanMFCC_11_interval\",\n",
        "            \"rmsWavelet_1_interval\",\"meanMFCC_5_interval\",\"mobility_interval\",\"sppw_whole\",\"energyDistribution_0_interval\",\n",
        "        ],\n",
        "        \"lgbm_features\": [\n",
        "            \"freqKurtEDA_whole\", \"freqKurtEDA_interval\",\"freqSkewEDA_interval\",\n",
        "            \"freqSkewEDA_whole\",\"skewMFCC_11_interval\",\"energyWavelet_4_interval\",\n",
        "            \"rmsWavelet_4_interval\",\"energyDistribution_0_whole\",\"energyWavelet_0_interval\",\n",
        "            \"stdMFCC_11_whole\", \"meanMFCC_12_whole\",\"stdMFCC_12_whole\",\n",
        "            \"energyWavelet_2_interval\",\"energyDistribution_2_interval\",\"spectralPowerBand(0.3-0.4)_interval\",\n",
        "            \"minSpectralPower_whole\",\"energyDistribution_6_whole\",\"stdMFCC_4_interval\",\n",
        "            \"meanMFCC_12_interval\",\"kurtMFCC_2_interval\",\"energyDistribution_8_interval\",\n",
        "            \"energyWavelet_3_interval\",\"spectralPowerBand(0.3-0.4)_whole\",\"kurtMFCC_4_interval\",\n",
        "            \"stdMFCC_0_interval\",\"energyWavelet_1_interval\",\"meanSecondDerivative_interval\",\n",
        "            \"skewMFCC_12_interval\",\"phasicPowers_0_interval\",\"auc_interval\",\n",
        "            \"energyDistribution_4_interval\",\"activity_interval\",\"spectralPowerBand(0.4-0.5)_interval\",\n",
        "            \"medianMFCC_11_interval\",\"rmsWavelet_3_interval\",\"stdMFCC_12_interval\",\n",
        "            \"medianMFCC_10_interval\",\"skewEDA_interval\",\"stdMFCC_10_whole\",\"rmsWavelet_0_interval\",\n",
        "            \"kurtMFCC_0_interval\", \"medianMFCC_12_interval\", \"stdMFCC_5_interval\",\"energyDistribution_2_whole\",\n",
        "            \"stdMFCC_10_interval\",\"varSpectralPower_interval\",\"hoc_2_whole\",\n",
        "            \"energyDistribution_1_whole\",\"kurtMFCC_12_whole\",\"meanSecondDerivative_whole\",\n",
        "        ],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Class for the Stacked SVR LGBM model\n",
        "class StackedSvrLgbmModel:\n",
        "    _lgbm_model: LGBMRegressor\n",
        "    _svr_model: SVR\n",
        "    _final_regressor: LinearRegression\n",
        "    svr_features: List[str]\n",
        "    lgbm_features: List[str]\n",
        "\n",
        "    def __init__(self,\n",
        "                 svr_features: List[str],\n",
        "                 lgbm_features: List[str],\n",
        "                 # SVR params\n",
        "                 kernel: str,\n",
        "                 degree: int,\n",
        "                 gamma: float,\n",
        "                 coef0: float,\n",
        "                 C: float,\n",
        "                 tol: float,\n",
        "                 epsilon: float,\n",
        "                 # LGBM params\n",
        "                 num_leaves: int,\n",
        "                 max_depth: int,\n",
        "                 learning_rate: float,\n",
        "                 n_estimators: int,\n",
        "                 min_child_samples: int,\n",
        "                 subsample: float,\n",
        "                 colsample_bytree: float):\n",
        "        self._lgbm_model = LGBMRegressor(n_estimators=n_estimators, num_leaves=num_leaves, max_depth=max_depth,\n",
        "                                         learning_rate=learning_rate, colsample_bytree=colsample_bytree,\n",
        "                                         min_child_samples=min_child_samples, subsample=subsample,\n",
        "                                         n_jobs=-1, boosting_type='dart', force_col_wise=True, verbosity=-1)\n",
        "        self._svr_model = SVR(kernel=kernel, degree=degree, gamma=gamma, coef0=coef0, tol=tol, C=C, epsilon=epsilon)\n",
        "        self._final_regressor = LinearRegression()\n",
        "\n",
        "        self.svr_features = svr_features\n",
        "        self.lgbm_features = lgbm_features\n",
        "\n",
        "    def train_and_val(self, train_df: pd.DataFrame, val_df: pd.DataFrame | None,\n",
        "                      Y_train: pd.DataFrame) -> pd.DataFrame | None:\n",
        "\n",
        "        X_train_svr = train_df[self.svr_features].to_numpy()\n",
        "        X_train_lgbm = train_df[self.lgbm_features].astype(float)\n",
        "\n",
        "        X_train_lgbm, X_val_lgbm, Y_final_regressor_train, Y_final_regressor_val = train_test_split(\n",
        "            X_train_lgbm,\n",
        "            Y_train,\n",
        "            test_size=0.1,\n",
        "            random_state=42)\n",
        "        X_train_svr, X_val_svr, _, _ = train_test_split(X_train_svr,\n",
        "                                                        Y_train,\n",
        "                                                        test_size=0.1,\n",
        "                                                        random_state=42)\n",
        "\n",
        "        self._lgbm_model.fit(X_train_lgbm, Y_final_regressor_train)\n",
        "        self._svr_model.fit(X_train_svr, Y_final_regressor_train)\n",
        "\n",
        "        Y_pred_lgbm_train = self._lgbm_model.predict(X_val_lgbm)\n",
        "        Y_pred_svr_train = self._svr_model.predict(X_val_svr)\n",
        "        X_final_regressor_train = np.column_stack([Y_pred_lgbm_train, Y_pred_svr_train])\n",
        "        self._final_regressor.fit(X_final_regressor_train, Y_final_regressor_val)\n",
        "\n",
        "        if val_df is not None:\n",
        "            X_test_svr = val_df[self.svr_features].to_numpy()\n",
        "            X_test_lgbm = val_df[self.lgbm_features].astype(float)\n",
        "\n",
        "            Y_pred_lgbm_test = self._lgbm_model.predict(X_test_lgbm)\n",
        "            Y_pred_svr_test = self._svr_model.predict(X_test_svr)\n",
        "            X_final_regressor_test = np.column_stack([Y_pred_lgbm_test, Y_pred_svr_test])\n",
        "            Y_pred = self._final_regressor.predict(X_final_regressor_test)\n",
        "            return Y_pred\n",
        "\n",
        "        return None\n",
        "\n",
        "    def test(self, test_df: pd.DataFrame):\n",
        "        X_test_svr = test_df[self.svr_features].to_numpy()\n",
        "        X_test_lgbm = test_df[self.lgbm_features].astype(float)\n",
        "\n",
        "        Y_pred_lgbm_test = self._lgbm_model.predict(X_test_lgbm)\n",
        "        Y_pred_svr_test = self._svr_model.predict(X_test_svr)\n",
        "\n",
        "        X_final_regressor_test = np.column_stack([Y_pred_lgbm_test, Y_pred_svr_test])\n",
        "        Y_pred = self._final_regressor.predict(X_final_regressor_test)\n",
        "\n",
        "        return Y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUGeCMS_AN_U"
      },
      "source": [
        "# Arousal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDXNkgyF_yXs"
      },
      "outputs": [],
      "source": [
        "# Loading the pupil arousal parameters\n",
        "pupil_arousal_params = pd.read_csv(os.path.join(home, \"pupil_params_arousal.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGsCMu2QSYvd"
      },
      "outputs": [],
      "source": [
        "def save_participant_predictions_arousal(df, gt_full_set, predictions_directory):\n",
        "    \"\"\"Run loop once and save modality predictions for each participant.\"\"\"\n",
        "    os.makedirs(predictions_directory, exist_ok=True)\n",
        "    predictions_path = os.path.join(predictions_directory, \"arousal_predictions.pkl\")\n",
        "\n",
        "    # If file already exists, skip recomputing\n",
        "    if os.path.exists(predictions_path):\n",
        "        print(f\"Predictions file already exists at {predictions_path}.\")\n",
        "        print(\"Delete the file if you want to rerun and overwrite predictions.\")\n",
        "        return predictions_path\n",
        "    participants = df[\"participant\"].unique()\n",
        "    all_predictions = {}\n",
        "\n",
        "    rmse_per_video = []\n",
        "    true_arousal_max = gt_full_set['Arousal'].max()\n",
        "    true_arousal_min = gt_full_set['Arousal'].min()\n",
        "\n",
        "    for test_pid in participants:\n",
        "        train_data, test_data = get_train_test_data(df, gt_full_set, test_pid, \"Arousal\")\n",
        "        if train_data is None or test_data is None:\n",
        "            continue\n",
        "\n",
        "        y_train = train_data[\"Arousal\"].values\n",
        "        y_test = test_data[\"Arousal\"].values\n",
        "\n",
        "        # Features\n",
        "        X_train_pupil = train_data[pupil_features]\n",
        "        X_test_pupil = test_data[pupil_features]\n",
        "\n",
        "        X_train_gsr = train_data[gsr_features]\n",
        "        X_test_gsr = test_data[gsr_features]\n",
        "\n",
        "        # ---------- PUPIL MODEL --------------\n",
        "        pupil_arousal_params['Participant'] = pupil_arousal_params['Participant'].astype(str)\n",
        "        test_pid_str = str(test_pid)\n",
        "\n",
        "        participant_params_row = pupil_arousal_params[pupil_arousal_params['Participant'] == test_pid_str]\n",
        "        if participant_params_row.empty:\n",
        "            model_pupil = LGBMRegressor(random_state=42)\n",
        "        else:\n",
        "            param_dict = participant_params_row.drop(columns=['Participant']).iloc[0].to_dict()\n",
        "            param_dict = {k: int(v) if isinstance(v, float) and v.is_integer() else v for k, v in param_dict.items()}\n",
        "            param_dict['random_state'] = 42\n",
        "            model_pupil = LGBMRegressor(**param_dict)\n",
        "\n",
        "        model_pupil.fit(X_train_pupil, y_train)\n",
        "        train_pupil_preds = model_pupil.predict(X_train_pupil)\n",
        "        test_pupil_preds = model_pupil.predict(X_test_pupil)\n",
        "\n",
        "        # --------- GSR MODEL ------------\n",
        "        model_gsr = StackedSvrLgbmModel(\n",
        "            svr_features=gsr_modality_configs[\"GSR_arousal\"][\"svr_features\"],\n",
        "            lgbm_features=gsr_modality_configs[\"GSR_arousal\"][\"lgbm_features\"],\n",
        "            **gsr_modality_configs[\"GSR_arousal\"][\"params\"]\n",
        "        )\n",
        "        model_gsr.train_and_val(X_train_gsr, None, y_train)\n",
        "        train_gsr_preds = model_gsr.test(X_train_gsr)\n",
        "        test_gsr_preds = model_gsr.test(X_test_gsr)\n",
        "\n",
        "        # -------- Save RMSEs ----------\n",
        "        for video_id, true_vals, pred_vals in zip(\n",
        "            test_data[\"video\"].unique(),\n",
        "            [test_data[test_data[\"video\"] == vid][\"Arousal\"].values for vid in test_data[\"video\"].unique()],\n",
        "            [test_pupil_preds[test_data[\"video\"] == vid] for vid in test_data[\"video\"].unique()],\n",
        "        ):\n",
        "            if len(true_vals) > 0 and len(pred_vals) > 0:\n",
        "                rmse_per_video.append({\n",
        "                    \"Participant\": test_pid,\n",
        "                    \"Video\": video_id,\n",
        "                    \"Modality\": \"Pupil\",\n",
        "                    \"RMSE\": np.sqrt(mean_squared_error(true_vals, pred_vals))\n",
        "                })\n",
        "\n",
        "        for video_id, true_vals, pred_vals in zip(\n",
        "            test_data[\"video\"].unique(),\n",
        "            [test_data[test_data[\"video\"] == vid][\"Arousal\"].values for vid in test_data[\"video\"].unique()],\n",
        "            [test_gsr_preds[test_data[\"video\"] == vid] for vid in test_data[\"video\"].unique()],\n",
        "        ):\n",
        "            if len(true_vals) > 0 and len(pred_vals) > 0:\n",
        "                rmse_per_video.append({\n",
        "                    \"Participant\": test_pid,\n",
        "                    \"Video\": video_id,\n",
        "                    \"Modality\": \"GSR\",\n",
        "                    \"RMSE\": np.sqrt(mean_squared_error(true_vals, pred_vals))\n",
        "                })\n",
        "\n",
        "        # --------- Store Predictions -----------\n",
        "        all_predictions[test_pid] = {\n",
        "            \"y_train\": y_train,\n",
        "            \"y_test\": y_test,\n",
        "            \"train_pupil_preds\": train_pupil_preds,\n",
        "            \"test_pupil_preds\": test_pupil_preds,\n",
        "            \"train_gsr_preds\": train_gsr_preds,\n",
        "            \"test_gsr_preds\": test_gsr_preds,\n",
        "        }\n",
        "\n",
        "    # Make sure directory exists\n",
        "    os.makedirs(predictions_directory, exist_ok=True)\n",
        "\n",
        "    # Save predictions\n",
        "    predictions_path = os.path.join(predictions_directory, \"arousal_predictions.pkl\")\n",
        "    joblib.dump(all_predictions, predictions_path)\n",
        "\n",
        "    # Save RMSE CSV\n",
        "    nrmse_df = pd.DataFrame(rmse_per_video)\n",
        "    nrmse_df[\"NRMSE\"] = nrmse_df[\"RMSE\"] / (true_arousal_max - true_arousal_min)\n",
        "    nrmse_df.to_csv(os.path.join(predictions_directory, \"nrmse_per_video_arousal.csv\"), index=False)\n",
        "\n",
        "    return predictions_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "eN37ukT1SwH1",
        "outputId": "6a0034f2-159e-4f28-8771-108d2ef086cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warning] Ground truth file not found for participant 22DFx at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_22DFx.csv\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10239\n",
            "[LightGBM] [Info] Number of data points in the train set: 1785, number of used features: 42\n",
            "[LightGBM] [Info] Start training from score 0.014344\n",
            "[Warning] Ground truth file not found for participant 5BJD3 at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_5BJD3.csv\n",
            "[Warning] Ground truth file not found for participant 9FGka at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_9FGka.csv\n",
            "[Warning] Ground truth file not found for participant EJOiBs at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_EJOiBs.csv\n",
            "[Warning] Ground truth file not found for participant Fk2oP at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_Fk2oP.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Data-Multimotion/Predictions/LOPO/arousal_predictions.pkl'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_participant_predictions_arousal(df, gt_full_set, predictions_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLtKlgXESjMF"
      },
      "outputs": [],
      "source": [
        "def run_participant_loop_arousal(predictions_directory, fusion_model_cls, fusion_model_kwargs={}):\n",
        "    \"\"\" Load saved predictions and run fusion model and evaluation.\"\"\"\n",
        "    predictions_path = os.path.join(predictions_directory, \"arousal_predictions.pkl\")\n",
        "    all_predictions = joblib.load(predictions_path)\n",
        "\n",
        "    participant_results = []\n",
        "    fusion_weights = {}\n",
        "    all_fusion_preds, all_true_values, all_test_participants = [], [], []\n",
        "\n",
        "    for test_pid, preds in all_predictions.items():\n",
        "        y_train = preds[\"y_train\"]\n",
        "        y_test = preds[\"y_test\"]\n",
        "\n",
        "        # Fusion inputs\n",
        "        fusion_X_train = np.vstack([preds[\"train_pupil_preds\"], preds[\"train_gsr_preds\"]]).T\n",
        "        fusion_X_test = np.vstack([preds[\"test_pupil_preds\"], preds[\"test_gsr_preds\"]]).T\n",
        "\n",
        "        # Normalize\n",
        "        fusion_scaler = StandardScaler()\n",
        "        fusion_X_train = fusion_scaler.fit_transform(fusion_X_train)\n",
        "        fusion_X_test = fusion_scaler.transform(fusion_X_test)\n",
        "\n",
        "        # Train fusion model\n",
        "        model_fusion = fusion_model_cls(**fusion_model_kwargs)\n",
        "        model_fusion.fit(fusion_X_train, y_train)\n",
        "        fusion_preds = model_fusion.predict(fusion_X_test)\n",
        "\n",
        "        # Save weights if linear model\n",
        "        if hasattr(model_fusion, \"coef_\"):\n",
        "            fusion_weights[test_pid] = model_fusion.coef_\n",
        "\n",
        "        # Evaluate\n",
        "        fusion_metrics = evaluate_fusion_model(y_test, fusion_preds)\n",
        "        fusion_metrics[\"participant\"] = test_pid\n",
        "        participant_results.append(fusion_metrics)\n",
        "\n",
        "        all_fusion_preds.extend(fusion_preds)\n",
        "        all_true_values.extend(y_test)\n",
        "        all_test_participants.extend([test_pid] * len(y_test))\n",
        "\n",
        "    return participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nLowxz64F0p"
      },
      "source": [
        "Next, testing different fusion models..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fFI2ogZ3oMy"
      },
      "source": [
        "**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azMYvN_MxYGb",
        "outputId": "d576fd42-9951-43fd-f0a9-dabf802d164d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 1 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.0870  0.9139  0.9844  0.0\n",
            "std   0.0567  0.1450  0.0545  0.0\n",
            "\n",
            "Excluded participants:\n",
            "  participant     NRMSE        R2      corr\n",
            "5        Bs73  0.564889 -1.511974 -0.977332\n",
            "\n",
            "Average Fusion Weights across Participants:\n",
            "Pupil_weight    0.0096\n",
            "GSR_weight      0.1842\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "fusion_model_cls = LinearRegression\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_arousal(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEworj-D4I2h"
      },
      "source": [
        "**Ridge Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwxlUxNWrFKV",
        "outputId": "18cc43a6-9e21-4eaa-eb7e-947b0c09d971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge --------------- Arousal\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 1 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.0869  0.9144  0.9846  0.0\n",
            "std   0.0565  0.1438  0.0539  0.0\n",
            "\n",
            "Excluded participants:\n",
            "  participant     NRMSE        R2      corr\n",
            "5        Bs73  0.564565 -1.509096 -0.977263\n",
            "\n",
            "Average Fusion Weights across Participants:\n",
            "Pupil_weight    0.0108\n",
            "GSR_weight      0.1829\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"Ridge --------------- Arousal\")\n",
        "fusion_model_cls = Ridge\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_arousal(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZyupyhz4LdZ"
      },
      "source": [
        "**Random Forest Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGZ50N7PrFPa",
        "outputId": "1f23102d-4b47-4961-c71b-9d19ccf8d677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF Regressor -------------- Arousal\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 1 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.0928  0.9056  0.9814  0.0\n",
            "std   0.0567  0.1555  0.0574  0.0\n",
            "\n",
            "Excluded participants:\n",
            "  participant     NRMSE       R2      corr\n",
            "5        Bs73  0.561797 -1.48455 -0.977599\n"
          ]
        }
      ],
      "source": [
        "print(\"RF Regressor -------------- Arousal\")\n",
        "fusion_model_cls = RandomForestRegressor\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_arousal(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W1qw4b24P3J"
      },
      "source": [
        "**Gradient Boosting Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2CSGS6-4RWN",
        "outputId": "03037a9c-d53c-425f-fd40-4b833ee15790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Regressor -------------- Arousal\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 1 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.0907  0.9087  0.9822  0.0\n",
            "std   0.0567  0.1560  0.0586  0.0\n",
            "\n",
            "Excluded participants:\n",
            "  participant     NRMSE        R2      corr\n",
            "5        Bs73  0.560362 -1.471876 -0.978696\n"
          ]
        }
      ],
      "source": [
        "print(\"Gradient Boosting Regressor -------------- Arousal\")\n",
        "fusion_model_cls = GradientBoostingRegressor\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_arousal(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VRa18md4Vtg"
      },
      "source": [
        "**SVR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvEj1hgmrFUO",
        "outputId": "541b8c27-ba7f-4a37-e068-9da0c6b7f4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVR -------------- Arousal\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 1 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.1083  0.8738  0.9813  0.0\n",
            "std   0.0638  0.1684  0.0383  0.0\n",
            "\n",
            "Excluded participants:\n",
            "  participant     NRMSE        R2      corr\n",
            "5        Bs73  0.586609 -1.708862 -0.972867\n"
          ]
        }
      ],
      "source": [
        "print(\"SVR -------------- Arousal\")\n",
        "fusion_model_cls = SVR\n",
        "fusion_model_kwargs = {'kernel':'rbf', 'C':1.0, 'epsilon':0.1}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_arousal(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ95Eo07AQAQ"
      },
      "source": [
        "# Valence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jcx3ley2D8G7"
      },
      "outputs": [],
      "source": [
        "# Loading the pupil arousal parameters\n",
        "pupil_valence_params = pd.read_csv(os.path.join(home, \"pupil_params_valence.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu-sleiGW9bL"
      },
      "outputs": [],
      "source": [
        "def save_participant_predictions_valence(df, gt_full_set, predictions_directory):\n",
        "    \"\"\" Run loop once and save modality predictions for each participant (Valence).\"\"\"\n",
        "    os.makedirs(predictions_directory, exist_ok=True)\n",
        "    predictions_path = os.path.join(predictions_directory, \"valence_predictions.pkl\")\n",
        "\n",
        "    # If file already exists, skip recomputing\n",
        "    if os.path.exists(predictions_path):\n",
        "        print(f\"Predictions file already exists at {predictions_path}.\")\n",
        "        print(\"Delete the file if you want to rerun and overwrite predictions.\")\n",
        "        return predictions_path\n",
        "\n",
        "    participants = df[\"participant\"].unique()\n",
        "    all_predictions = {}\n",
        "\n",
        "    rmse_per_video = []\n",
        "    true_valence_max = gt_full_set['Valence'].max()\n",
        "    true_valence_min = gt_full_set['Valence'].min()\n",
        "\n",
        "    for test_pid in participants:\n",
        "        train_data, test_data = get_train_test_data(df, gt_full_set, test_pid, \"Valence\")\n",
        "        if train_data is None or test_data is None:\n",
        "            continue\n",
        "\n",
        "        y_train = train_data[\"Valence\"].values\n",
        "        y_test = test_data[\"Valence\"].values\n",
        "\n",
        "        # Features\n",
        "        X_train_pupil = train_data[pupil_features]\n",
        "        X_test_pupil = test_data[pupil_features]\n",
        "\n",
        "        X_train_gsr = train_data[gsr_features]\n",
        "        X_test_gsr = test_data[gsr_features]\n",
        "\n",
        "        # ------------ PUPIL MODEL --------------\n",
        "        pupil_valence_params['Participant'] = pupil_valence_params['Participant'].astype(str)\n",
        "        test_pid_str = str(test_pid)\n",
        "\n",
        "        participant_params_row = pupil_valence_params[pupil_valence_params['Participant'] == test_pid_str]\n",
        "        if participant_params_row.empty:\n",
        "            print(f\"No parameters found for participant {test_pid_str}. Using default.\")\n",
        "            model_pupil = LGBMRegressor(objective='quantile', alpha=0.5, random_state=42)\n",
        "        else:\n",
        "            param_dict = participant_params_row.drop(columns=['Participant']).iloc[0].to_dict()\n",
        "            param_dict = {k: int(v) if isinstance(v, float) and v.is_integer() else v for k, v in param_dict.items()}\n",
        "            param_dict['random_state'] = 42\n",
        "            param_dict['objective'] = 'quantile'\n",
        "            param_dict['alpha'] = 0.5\n",
        "            model_pupil = LGBMRegressor(**param_dict)\n",
        "\n",
        "        model_pupil.fit(X_train_pupil, y_train)\n",
        "        train_pupil_preds = model_pupil.predict(X_train_pupil)\n",
        "        test_pupil_preds = model_pupil.predict(X_test_pupil)\n",
        "\n",
        "        # ------------ GSR MODEL -------------\n",
        "        model_gsr = StackedSvrLgbmModel(\n",
        "            svr_features=gsr_modality_configs[\"GSR_valence\"][\"svr_features\"],\n",
        "            lgbm_features=gsr_modality_configs[\"GSR_valence\"][\"lgbm_features\"],\n",
        "            **gsr_modality_configs[\"GSR_valence\"][\"params\"]\n",
        "        )\n",
        "        model_gsr.train_and_val(X_train_gsr, None, y_train)\n",
        "        train_gsr_preds = model_gsr.test(X_train_gsr)\n",
        "        test_gsr_preds = model_gsr.test(X_test_gsr)\n",
        "\n",
        "        # ---------- Save RMSEs -------------\n",
        "        for video_id, true_vals, pred_vals in zip(\n",
        "            test_data[\"video\"].unique(),\n",
        "            [test_data[test_data[\"video\"] == vid][\"Valence\"].values for vid in test_data[\"video\"].unique()],\n",
        "            [test_pupil_preds[test_data[\"video\"] == vid] for vid in test_data[\"video\"].unique()],\n",
        "        ):\n",
        "            if len(true_vals) > 0 and len(pred_vals) > 0:\n",
        "                rmse_per_video.append({\n",
        "                    \"Participant\": test_pid,\n",
        "                    \"Video\": video_id,\n",
        "                    \"Modality\": \"Pupil\",\n",
        "                    \"RMSE\": np.sqrt(mean_squared_error(true_vals, pred_vals))\n",
        "                })\n",
        "\n",
        "        for video_id, true_vals, pred_vals in zip(\n",
        "            test_data[\"video\"].unique(),\n",
        "            [test_data[test_data[\"video\"] == vid][\"Valence\"].values for vid in test_data[\"video\"].unique()],\n",
        "            [test_gsr_preds[test_data[\"video\"] == vid] for vid in test_data[\"video\"].unique()],\n",
        "        ):\n",
        "            if len(true_vals) > 0 and len(pred_vals) > 0:\n",
        "                rmse_per_video.append({\n",
        "                    \"Participant\": test_pid,\n",
        "                    \"Video\": video_id,\n",
        "                    \"Modality\": \"GSR\",\n",
        "                    \"RMSE\": np.sqrt(mean_squared_error(true_vals, pred_vals))\n",
        "                })\n",
        "\n",
        "        # -------- Store Predictions ---------\n",
        "        all_predictions[test_pid] = {\n",
        "            \"y_train\": y_train,\n",
        "            \"y_test\": y_test,\n",
        "            \"train_pupil_preds\": train_pupil_preds,\n",
        "            \"test_pupil_preds\": test_pupil_preds,\n",
        "            \"train_gsr_preds\": train_gsr_preds,\n",
        "            \"test_gsr_preds\": test_gsr_preds,\n",
        "        }\n",
        "\n",
        "    # Make sure directory exists\n",
        "    os.makedirs(predictions_directory, exist_ok=True)\n",
        "\n",
        "    # Save predictions\n",
        "    predictions_path = os.path.join(predictions_directory, \"valence_predictions.pkl\")\n",
        "    joblib.dump(all_predictions, predictions_path)\n",
        "\n",
        "    # Save RMSE CSV\n",
        "    nrmse_df = pd.DataFrame(rmse_per_video)\n",
        "    nrmse_df[\"NRMSE\"] = nrmse_df[\"RMSE\"] / (true_valence_max - true_valence_min)\n",
        "    nrmse_df.to_csv(os.path.join(predictions_directory, \"nrmse_per_video_valence.csv\"), index=False)\n",
        "\n",
        "    return predictions_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "CIe1zmx0YPNx",
        "outputId": "0203a2c7-b75c-47da-d2e0-a2ed99fd9f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warning] Ground truth file not found for participant 22DFx at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_22DFx.csv\n",
            "[Warning] Ground truth file not found for participant 5BJD3 at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_5BJD3.csv\n",
            "[Warning] Ground truth file not found for participant 9FGka at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_9FGka.csv\n",
            "[Warning] Ground truth file not found for participant EJOiBs at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_EJOiBs.csv\n",
            "[Warning] Ground truth file not found for participant Fk2oP at: /content/drive/MyDrive/Data-Multimotion/Ground truth/Leave-one-out/individual_ground_truth_no_Fk2oP.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Data-Multimotion/Predictions/LOPO/valence_predictions.pkl'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_participant_predictions_valence(df, gt_full_set, predictions_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlDjWx-uX91h"
      },
      "outputs": [],
      "source": [
        "def run_participant_loop_valence(predictions_directory, fusion_model_cls, fusion_model_kwargs={}):\n",
        "    \"\"\" Load saved predictions and run fusion model and evaluation for valence.\"\"\"\n",
        "    predictions_path = os.path.join(predictions_directory, \"valence_predictions.pkl\")\n",
        "    all_predictions = joblib.load(predictions_path)\n",
        "\n",
        "    participant_results = []\n",
        "    fusion_weights = {}\n",
        "    all_fusion_preds, all_true_values, all_test_participants = [], [], []\n",
        "\n",
        "    for test_pid, preds in all_predictions.items():\n",
        "        y_train = preds[\"y_train\"]\n",
        "        y_test = preds[\"y_test\"]\n",
        "\n",
        "        # Fusion inputs\n",
        "        fusion_X_train = np.vstack([preds[\"train_pupil_preds\"], preds[\"train_gsr_preds\"]]).T\n",
        "        fusion_X_test = np.vstack([preds[\"test_pupil_preds\"], preds[\"test_gsr_preds\"]]).T\n",
        "\n",
        "        # Normalize\n",
        "        fusion_scaler = StandardScaler()\n",
        "        fusion_X_train = fusion_scaler.fit_transform(fusion_X_train)\n",
        "        fusion_X_test = fusion_scaler.transform(fusion_X_test)\n",
        "\n",
        "        # Train fusion model\n",
        "        model_fusion = fusion_model_cls(**fusion_model_kwargs)\n",
        "        model_fusion.fit(fusion_X_train, y_train)\n",
        "        fusion_preds = model_fusion.predict(fusion_X_test)\n",
        "\n",
        "        # Save weights if linear model\n",
        "        if hasattr(model_fusion, \"coef_\"):\n",
        "            fusion_weights[test_pid] = model_fusion.coef_\n",
        "\n",
        "        # Evaluate\n",
        "        fusion_metrics = evaluate_fusion_model(y_test, fusion_preds)\n",
        "        fusion_metrics[\"participant\"] = test_pid\n",
        "        participant_results.append(fusion_metrics)\n",
        "\n",
        "        all_fusion_preds.extend(fusion_preds)\n",
        "        all_true_values.extend(y_test)\n",
        "        all_test_participants.extend([test_pid] * len(y_test))\n",
        "\n",
        "    return participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CnNK-225KjD"
      },
      "source": [
        "Next, testing different fusion models..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUwR-fDd5Nos"
      },
      "source": [
        "**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QMsQeysHxbc",
        "outputId": "a09e681c-ce49-446b-e23e-e32004014660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 0 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.1224  0.8072  0.9743  0.0\n",
            "std   0.0771  0.2891  0.0390  0.0\n",
            "\n",
            "Excluded participants:\n",
            "Empty DataFrame\n",
            "Columns: [participant, NRMSE, R2, corr]\n",
            "Index: []\n",
            "\n",
            "Average Fusion Weights across Participants:\n",
            "Pupil_weight    0.0656\n",
            "GSR_weight      0.2839\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "fusion_model_cls = LinearRegression\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_valence(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuzAYcWF5QYa"
      },
      "source": [
        "**Ridge Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3Bs3mPZvRPW",
        "outputId": "a58c4c62-78e6-4aa0-e636-ad68afa627f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge --------------- Valence\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 0 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.1224  0.8075  0.9743  0.0\n",
            "std   0.0769  0.2884  0.0388  0.0\n",
            "\n",
            "Excluded participants:\n",
            "Empty DataFrame\n",
            "Columns: [participant, NRMSE, R2, corr]\n",
            "Index: []\n",
            "\n",
            "Average Fusion Weights across Participants:\n",
            "Pupil_weight    0.0666\n",
            "GSR_weight      0.2827\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"Ridge --------------- Valence\")\n",
        "fusion_model_cls = Ridge\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_valence(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crjLOC745V2J"
      },
      "source": [
        "**Random Forest Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM-shmU_vRZt",
        "outputId": "2876bfe1-cf28-40a3-8a64-7daecce2f22e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF Regressor -------------- Valence\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 0 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.1302  0.7819  0.9689  0.0\n",
            "std   0.0819  0.3151  0.0536  0.0\n",
            "\n",
            "Excluded participants:\n",
            "Empty DataFrame\n",
            "Columns: [participant, NRMSE, R2, corr]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(\"RF Regressor -------------- Valence\")\n",
        "fusion_model_cls = RandomForestRegressor\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_valence(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-44H-dIQ5YWo"
      },
      "source": [
        "**Gradient Boosting Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bw3umMFvRcU",
        "outputId": "95a1dadb-9bb5-40b7-bb40-3bf577d8d27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Regressor -------------- Valence\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 0 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.1257  0.7971  0.9723  0.0\n",
            "std   0.0787  0.2911  0.0473  0.0\n",
            "\n",
            "Excluded participants:\n",
            "Empty DataFrame\n",
            "Columns: [participant, NRMSE, R2, corr]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(\"Gradient Boosting Regressor -------------- Valence\")\n",
        "fusion_model_cls = GradientBoostingRegressor\n",
        "fusion_model_kwargs = {}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_valence(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZwOP6yw5bRA"
      },
      "source": [
        "**SVR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_mYTjT2vRee",
        "outputId": "19269fe9-b336-4ca6-dfbb-f453223ae90a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVR -------------- Valence\n",
            "\n",
            "=== Summary (Excluding Outliers) ===\n",
            "\n",
            "Filtered out 0 out of 51 participants.\n",
            "       NRMSE      R2    corr    p\n",
            "mean  0.1258  0.7933  0.9742  0.0\n",
            "std   0.0814  0.3077  0.0361  0.0\n",
            "\n",
            "Excluded participants:\n",
            "Empty DataFrame\n",
            "Columns: [participant, NRMSE, R2, corr]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(\"SVR -------------- Valence\")\n",
        "fusion_model_cls = SVR\n",
        "fusion_model_kwargs = {'kernel':'rbf', 'C':1.0, 'epsilon':0.1}\n",
        "\n",
        "participant_results, fusion_weights, all_fusion_preds, all_true_values, all_test_participants = run_participant_loop_valence(predictions_directory, fusion_model_cls, fusion_model_kwargs)\n",
        "\n",
        "results_df = pd.DataFrame(participant_results)\n",
        "print_filtered_summary(results_df)\n",
        "print_fusion_weights_summary(fusion_weights)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
